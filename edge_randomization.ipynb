{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from NEMtropy import DirectedGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# @formatter:off\n",
    "%store -r df_airports\n",
    "%store -r airports_dict\n",
    "%store -r df_merged\n",
    "# @formatter:on\n",
    "GG = nx.read_gml('Graphs/airlines.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# build dbcm - directed binary configuration model, samples from distribution\n",
    "adj_g = nx.to_numpy_array(GG)\n",
    "edges = np.array(GG.edges)\n",
    "graph_d = DirectedGraph(edgelist=edges)\n",
    "graph_d.solve_tool(model=\"dcm_exp\")\n",
    "graph_d.ensemble_sampler(1, cpu_n=4, output_dir='dbcm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read sample\n",
    "edgelist_dbcm = np.loadtxt(f\"dbcm/0.txt\", dtype=str)\n",
    "GG_RANDOMIZED = nx.DiGraph()\n",
    "GG_RANDOMIZED.add_edges_from(edgelist_dbcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# measure centrality measures\n",
    "degree_centrality = nx.degree_centrality(GG)\n",
    "closeness_centrality = nx.closeness_centrality(GG)\n",
    "betweenness_centrality = nx.betweenness_centrality(GG)\n",
    "eigenvector_centrality = nx.eigenvector_centrality(GG)\n",
    "\n",
    "# set node attributes\n",
    "nx.set_node_attributes(GG, closeness_centrality, 'closeness centrality')\n",
    "nx.set_node_attributes(GG, degree_centrality, 'degree centrality')\n",
    "nx.set_node_attributes(GG, betweenness_centrality, 'betweenness centrality')\n",
    "nx.set_node_attributes(GG, eigenvector_centrality, 'eigenvector centrality')\n",
    "\n",
    "# build arrays for easier plotting\n",
    "centralityArr = [degree_centrality, closeness_centrality,\n",
    "                 betweenness_centrality, eigenvector_centrality]\n",
    "centralityNames = ['degree', 'closeness', 'betweenness', 'eigenvector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# measure centrality measures of randomized\n",
    "degree_centrality_RAND = nx.degree_centrality(GG_RANDOMIZED)\n",
    "closeness_centrality_RAND = nx.closeness_centrality(GG_RANDOMIZED)\n",
    "betweenness_centrality_RAND = nx.betweenness_centrality(GG_RANDOMIZED)\n",
    "eigenvector_centrality_RAND = nx.eigenvector_centrality(GG_RANDOMIZED)\n",
    "\n",
    "nx.set_node_attributes(GG_RANDOMIZED, closeness_centrality, 'closeness centrality')\n",
    "nx.set_node_attributes(GG_RANDOMIZED, degree_centrality, 'degree centrality')\n",
    "nx.set_node_attributes(GG_RANDOMIZED, betweenness_centrality, 'betweenness centrality')\n",
    "nx.set_node_attributes(GG_RANDOMIZED, eigenvector_centrality, 'eigenvector centrality')\n",
    "\n",
    "# build arrays for easier plotting\n",
    "centralityArrRAND = [degree_centrality_RAND, closeness_centrality_RAND,\n",
    "                 betweenness_centrality_RAND, eigenvector_centrality_RAND]\n",
    "centralityNames = ['degree', 'closeness', 'betweenness', 'eigenvector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dbcm takes as constraint in & out degree. visualize as reference.\n",
    "\n",
    "G_DEGS = [GG.degree()[i] for i in GG.nodes()]\n",
    "G_DEGS_RAND = [GG_RANDOMIZED.degree()[i] for i in GG_RANDOMIZED.nodes()]\n",
    "fig = plt.figure(dpi=300)\n",
    "ax = sns.kdeplot(G_DEGS,alpha=0.5)\n",
    "sns.kdeplot(G_DEGS_RAND, ax=ax, alpha=0.5)\n",
    "plt.title('Degree Distribution')\n",
    "plt.show()\n",
    "\n",
    "GG_in_degree_dict = dict(GG.in_degree)\n",
    "G_DEGS = [ GG_in_degree_dict[i] for i in GG.nodes() ]\n",
    "GG_in_degree_dict = dict(GG_RANDOMIZED.in_degree)\n",
    "G_DEGS_RAND = [ GG_in_degree_dict[i] for i in GG_RANDOMIZED.nodes() ]\n",
    "\n",
    "fig = plt.figure(dpi=300)\n",
    "ax = sns.kdeplot(G_DEGS,alpha=0.5)\n",
    "sns.kdeplot(G_DEGS_RAND, ax=ax, alpha=0.5)\n",
    "plt.title('In Degree Distribution')\n",
    "plt.show()\n",
    "\n",
    "GG_in_degree_dict = dict(GG.out_degree)\n",
    "G_DEGS = [ GG_in_degree_dict[i] for i in GG.nodes() ]\n",
    "GG_in_degree_dict = dict(GG_RANDOMIZED.out_degree)\n",
    "G_DEGS_RAND = [ GG_in_degree_dict[i] for i in GG_RANDOMIZED.nodes() ]\n",
    "\n",
    "fig = plt.figure(dpi=300)\n",
    "ax = sns.kdeplot(G_DEGS,alpha=0.5)\n",
    "sns.kdeplot(G_DEGS_RAND, ax=ax, alpha=0.5)\n",
    "plt.title('Out Degree Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "myarray = list(betweenness_centrality.values())\n",
    "\n",
    "print(np.isnan(myarray).any())\n",
    "print(np.isinf(myarray).any())\n",
    "mm = min(myarray)\n",
    "\n",
    "# note => have 0's, cannot use log here !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stat='density'\n",
    "# build centrality comparison subplots.\n",
    "# if using seaborn, not need to use log space for binning => https://stackoverflow.com/questions/69573823/log-scale-true-in-seaborn-histplot\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12,8), constrained_layout=True)\n",
    "axes[0,0].set_title('Degree centrality', fontsize=20)\n",
    "ax = sns.histplot(degree_centrality.values(),alpha=0.5, ax=axes[0,0], label='Original', bins=20, log_scale=(True, True), stat=stat)\n",
    "sns.histplot(degree_centrality_RAND.values(), ax=ax, alpha=0.5, label='Randomized', palette='Accent', bins=20, log_scale=(True, True), stat=stat)\n",
    "axes[0,0].legend(loc='upper right')\n",
    "\n",
    "arr = np.array(list(betweenness_centrality.values()))\n",
    "arrRand = np.array(list(betweenness_centrality_RAND.values()))\n",
    "\n",
    "ax = sns.histplot(betweenness_centrality.values(), alpha=0.5, ax=axes[0,1], label='Original', log_scale=(False, True), bins=20, stat=stat)\n",
    "sns.histplot(betweenness_centrality_RAND.values(), ax=ax, alpha=0.5, label='Randomized',  log_scale=(False, True), palette='Accent', bins=20,stat=stat)\n",
    "axes[0,1].set_title('Betweenness centrality', fontsize=20)\n",
    "axes[0,1].legend(loc='upper right')\n",
    "#\n",
    "axes[1,0].set_title('Eigenvector centrality', fontsize=20)\n",
    "ax = sns.histplot(eigenvector_centrality.values(),alpha=0.5, ax=axes[1,0], label='Original', stat=stat, log_scale=(False, True), bins=30)\n",
    "sns.histplot(eigenvector_centrality_RAND.values(), ax=ax, alpha=0.5, label='Randomized', stat=stat, log_scale=(False, True), palette='Accent', bins=30)\n",
    "axes[1,0].legend(loc='upper right')\n",
    "#\n",
    "\n",
    "axes[1,1].set_title('Closeness centrality', fontsize=20)\n",
    "ax = sns.histplot(closeness_centrality.values(), alpha=0.5, ax=axes[1,1], label='Original', stat=stat, log_scale=(False, True), bins=30)\n",
    "sns.histplot(closeness_centrality_RAND.values(), ax=ax, alpha=0.5, label='Randomized', stat=stat, log_scale=(False, True), palette='Accent', bins=30)\n",
    "axes[1,1].legend(loc='upper right')\n",
    "#\n",
    "plt.savefig(f'Figures/centrality_comparison.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print average closeness centrality for reference.\n",
    "print(f'Average closeness centrality: {np.average(list(closeness_centrality.values())):.4f}')\n",
    "print(f'Average closeness centrality (randomized): {np.average(list(closeness_centrality_RAND.values())):.4f}')\n",
    "\n",
    "# print average betweenness centrality for reference.\n",
    "print(f'Average betweenness centrality: {np.average(list(betweenness_centrality.values())):.4f}')\n",
    "print(f'Average betweenness centrality (randomized): {np.average(list(betweenness_centrality_RAND.values())):.4f}')\n",
    "\n",
    "# print average eigenvector centrality for reference.\n",
    "print(f'Average eigenvector centrality: {np.average(list(eigenvector_centrality.values())):.4f}')\n",
    "print(f'Average eigenvector centrality (randomized): {np.average(list(eigenvector_centrality_RAND.values())):.4f}')\n",
    "\n",
    "# print average closeness centrality for reference.\n",
    "print(f'Average closeness centrality: {np.average(list(closeness_centrality.values())):.4f}')\n",
    "print(f'Average closeness centrality (randomized): {np.average(list(closeness_centrality_RAND.values())):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Due to high average degree, little differences are discernible.\n",
    "so even though we reshuffle the edges and the nodes essentially lose their meaning\n",
    "(nodes are results from random draws from samples, so even though we can reassign their original identity, they don't mean anything)\n",
    ", the centralities don't change that much, because the fundamental degree distribution remains more or less the same.\n",
    "This also means, applied to the context of airports, that just performing a random draw of a air traffic network,\n",
    "we don't see any signficant differences, at least regarding to the centrality measures.\n",
    "Or in other words, there is no reason, why an airport `Charles the Gaulle` should be a hub, and not some provincial airport in Greenland,\n",
    "other than the underlying infrastructural, historical and cultural context, so everything except the airports themselves is important.\n",
    "\n",
    "Even though the average closeness centrality significantly, looking at the density functions, there are some meaningful changes,\n",
    "i.e. over 0.1 the distribution has been shifted by not an insignificant amount, though,\n",
    "on average, that seems to be cancelled out by the higher density distribution around 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# if want to check individual nodes, we need to remap node id's.\n",
    "# directed graph class uses different node indices than what we originally had.\n",
    "\n",
    "# need to remap to our airport ids back to be able to do comparisons.\n",
    "degree_centrality_RAND2 = {}\n",
    "for k,v in degree_centrality_RAND.items():\n",
    "    realkey = graph_d.nodes_dict.get(int(k))\n",
    "    degree_centrality_RAND2[realkey] = v\n",
    "\n",
    "# set to 0 if does not exist\n",
    "degree_centrality_RAND3 = copy.deepcopy(degree_centrality_RAND2)\n",
    "for k,v in degree_centrality.items():\n",
    "    if not k in degree_centrality_RAND3:\n",
    "        degree_centrality_RAND3[k] = 0\n",
    "\n",
    "# betweenness\n",
    "betweenness_centrality_RAND2 = {}\n",
    "for k,v in betweenness_centrality_RAND.items():\n",
    "    realkey = graph_d.nodes_dict.get(int(k))\n",
    "    betweenness_centrality_RAND2[realkey] = v\n",
    "\n",
    "# set to 0 if does not exist\n",
    "betweenness_centrality_RAND3 = copy.deepcopy(betweenness_centrality_RAND2)\n",
    "for k,v in betweenness_centrality.items():\n",
    "    if not k in betweenness_centrality_RAND3:\n",
    "        betweenness_centrality_RAND3[k] = 0\n",
    "\n",
    "# eigenv\n",
    "eigenvector_centrality_RAND2 = {}\n",
    "for k,v in eigenvector_centrality_RAND.items():\n",
    "    realkey = graph_d.nodes_dict.get(int(k))\n",
    "    eigenvector_centrality_RAND2[realkey] = v\n",
    "\n",
    "# set to 0 if does not exist\n",
    "eigenvector_centrality_RAND3 = copy.deepcopy(eigenvector_centrality_RAND2)\n",
    "for k,v in eigenvector_centrality.items():\n",
    "    if not k in eigenvector_centrality_RAND3:\n",
    "        eigenvector_centrality_RAND3[k] = 0\n",
    "\n",
    "# closeness\n",
    "closeness_centrality_RAND2 = {}\n",
    "for k,v in closeness_centrality_RAND.items():\n",
    "    realkey = graph_d.nodes_dict.get(int(k))\n",
    "    closeness_centrality_RAND2[realkey] = v\n",
    "\n",
    "# set to 0 if does not exist\n",
    "closeness_centrality_RAND3 = copy.deepcopy(closeness_centrality_RAND2)\n",
    "for k,v in closeness_centrality.items():\n",
    "    if not k in closeness_centrality_RAND3:\n",
    "        closeness_centrality_RAND3[k] = 0\n",
    "\n",
    "fig = plt.figure(dpi=300)\n",
    "plt.scatter(degree_centrality.values(), degree_centrality_RAND3.values(), alpha=0.3)\n",
    "plt.title('Degree Centrality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "degreeArr = [v for k,v in degree_centrality.items()]\n",
    "degreeArrR = [v for k,v in degree_centrality_RAND3.items()]\n",
    "closenessArr = [v for k,v in closeness_centrality.items()]\n",
    "closenessArrR = [v for k,v in closeness_centrality_RAND3.items()]\n",
    "betweennessArr = [v for k,v in betweenness_centrality.items()]\n",
    "betweennessArrR = [v for k,v in betweenness_centrality_RAND3.items()]\n",
    "eigenvArr = [v for k,v in eigenvector_centrality.items()]\n",
    "eigenvArrR = [v for k,v in eigenvector_centrality_RAND3.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compute betweenness scores\n",
    "peaDegree = sp.stats.pearsonr(betweennessArr,betweennessArrR)[0]\n",
    "peaBetweenness = sp.stats.pearsonr(degreeArr,degreeArrR)[0]\n",
    "peaCloseness = sp.stats.pearsonr(closenessArr,closenessArrR)[0]\n",
    "peaEigenv = sp.stats.pearsonr(eigenvArr,eigenvArrR)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# scatter plots of randomized vs original with additional pearson's correlation shown between the two.\n",
    "\n",
    "# note: randomization should not lose nodes using dbcm. this result is therefore meaningless.\n",
    "llim=0\n",
    "ulim=0.5\n",
    "fig, axs = plt.subplots(2, 2, constrained_layout=True, figsize=(12,10))\n",
    "axs[0,0].scatter(betweennessArr, betweennessArrR, label=f\"$r={peaBetweenness:.2f}$\", s=10, alpha=0.6)\n",
    "axs[0,0].set_xlabel('Betweenness' , fontsize=14)\n",
    "axs[0,0].set_ylabel('Betweenness - Randomized', fontsize=14)\n",
    "axs[0,0].legend(loc='upper left', frameon=True, fontsize=24)\n",
    "axs[0,0].set_xlim(llim, ulim)\n",
    "axs[0,0].set_ylim(llim, ulim)\n",
    "\n",
    "axs[0,1].scatter(degreeArr, degreeArrR, label=f\"$r={peaDegree:.2f}$\", s=10, alpha=0.6)\n",
    "axs[0,1].set_xlabel('Degree' , fontsize=14)\n",
    "axs[0,1].set_ylabel('Degree - Randomized', fontsize=14)\n",
    "axs[0,1].legend(loc='upper left', frameon=True, fontsize=24)\n",
    "axs[0,1].set_xlim(llim, ulim)\n",
    "axs[0,1].set_ylim(llim, ulim)\n",
    "\n",
    "axs[1,0].scatter(closenessArr, closenessArrR, label=f\"$r={peaCloseness:.2f}$\",s=10, alpha=0.6)\n",
    "axs[1,0].set_xlabel('Closeness' , fontsize=14)\n",
    "axs[1,0].set_ylabel('Closeness - Randomized', fontsize=14)\n",
    "axs[1,0].legend(loc='upper left', frameon=True, fontsize=24)\n",
    "axs[1,0].set_xlim(llim, ulim)\n",
    "axs[1,0].set_ylim(llim, ulim)\n",
    "\n",
    "axs[1,1].scatter(eigenvArr, eigenvArrR, label=f\"$r={peaEigenv:.2f}$\", s=10, alpha=0.6)\n",
    "axs[1,1].set_xlabel('Eigenvector' , fontsize=14)\n",
    "axs[1,1].set_ylabel('Eigenvector - Randomized', fontsize=14)\n",
    "axs[1,1].legend(loc='upper left', frameon=True, fontsize=24)\n",
    "axs[1,1].set_xlim(llim, ulim)\n",
    "axs[1,1].set_ylim(llim, ulim)\n",
    "plt.suptitle('Centrality Comparison Original - Randomized', fontsize=24)\n",
    "# plt.savefig(f'Figures/centrality_scatters.pdf', dpi=300)\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
