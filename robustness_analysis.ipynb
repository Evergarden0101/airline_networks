{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3c8rz4yABQu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "import random\n",
    "from collections import OrderedDict \n",
    "from tqdm import trange\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySw4lb4wABQz"
   },
   "source": [
    "# Network Robustness Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QKBVoqhABQ1"
   },
   "source": [
    "Questions: \n",
    "- How many nodes can we remove while the network preserves its functioning condition?\n",
    "- How many nodes do we need to remove to fragment the network into isolated components?\n",
    "\n",
    "*Notes: \n",
    "- Attack order was computed beforehand instead of on the fly, because it drastically increased computation time.\n",
    "- Should we take avg. or max. values?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ui9lIsL_ABQ2"
   },
   "outputs": [],
   "source": [
    "G = nx.read_gml('Graphs/airlines.gml')\n",
    "# 1% of data (rounded, 14 nodes will be left at the end)\n",
    "REMOVAL_SIZE = int(len(G)/100)\n",
    "# upper bound % of node to be removed\n",
    "REMOVAL_COUNT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKY4fkkaABQ3"
   },
   "outputs": [],
   "source": [
    "def percentage_of_removed_links(G):\n",
    "    return int(len(G)/100)\n",
    "\n",
    "def random_attack(g, removal_size, node_removal_algorithm, img_name):\n",
    "    \n",
    "    graph = g.copy()\n",
    "    # network metrics\n",
    "    degree = []\n",
    "    #avg_out_degree = []\n",
    "    SCC = []\n",
    "    avg_closeness = []\n",
    "    avg_betweenness = []\n",
    "    avg_clustering = []\n",
    "    avg_eigvec_centrality = []\n",
    "    num_of_steps = []\n",
    "    \n",
    "    for percentage in trange(REMOVAL_COUNT):\n",
    "        # compute avg. degree\n",
    "        degree.append(sum([d for (n, d) in nx.degree(graph)]) / float(graph.number_of_nodes()))\n",
    "        #avg_out_degree.append(sum([d for (n, d) in graph.out_degree()]) / float(graph.number_of_nodes()))\n",
    "        # clustering\n",
    "        avg_clustering.append(nx.average_clustering(graph))\n",
    "        # largest strongly connected components\n",
    "        SCC.append(len(max(nx.strongly_connected_components(graph), key=len)))\n",
    "        # closeness\n",
    "        avg_closeness.append(np.average(list(nx.closeness_centrality(graph).values())))\n",
    "        # betweenness\n",
    "        avg_betweenness.append(np.average(list(nx.betweenness_centrality(graph).values())))\n",
    "        # eigenvector centrality (DOES NOT CONVERGE!)\n",
    "        #avg_eigvec_centrality.append(np.average(list(nx.eigenvector_centrality(graph).values())))\n",
    "        # remove node according to given node removal algorithm\n",
    "        # remove node at random\n",
    "        for i in range(removal_size):\n",
    "            target = random.choice(list(graph.nodes.keys()))\n",
    "            graph.remove_node(target)\n",
    "        # keep track of steps\n",
    "        num_of_steps.append(percentage)\n",
    "    \n",
    "    # plot statistics\n",
    "    fig, axs = plt.subplots(3, figsize=(15,15))\n",
    "    fig.suptitle('Network statistics after attack')\n",
    "    axs[0].plot(num_of_steps, degree, color='blue', label='avg. degree')\n",
    "    #axs[0].plot(num_of_steps, avg_out_degree, color='cyan', label='avg. out degree')\n",
    "    axs[0].legend()\n",
    "    axs[0].set_ylabel('k')\n",
    "    axs[0].set_xlabel('% of removed nodes')\n",
    "    axs[0].set_yscale('log')\n",
    "    axs[1].plot(num_of_steps, SCC, color='red', label='SCC')\n",
    "    axs[1].set_ylabel('Giant component size')\n",
    "    axs[1].set_xlabel('% of removed nodes')\n",
    "    axs[1].set_yscale('log')\n",
    "    axs[1].legend()\n",
    "    axs[2].plot(num_of_steps, avg_closeness, color='green', label='avg. closeness')\n",
    "    axs[2].plot(num_of_steps, avg_betweenness, color='orange', label='avg. betweenness')\n",
    "    axs[2].plot(num_of_steps, avg_clustering, color='purple', label='avg. clustering')\n",
    "    #axs[2].plot(num_of_steps, avg_eigvec_centrality, color='brown', label='avg. eigvec. centr.')\n",
    "    axs[2].set_ylabel('CC,CB,C,EC')\n",
    "    axs[2].set_xlabel('% of removed nodes')\n",
    "    axs[2].set_yscale('log')\n",
    "    axs[2].legend()\n",
    "    fig.savefig('Figures/robustness/' + img_name)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vZJUXhCABQ5"
   },
   "source": [
    "## Random Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uhP5VXPDABQ6"
   },
   "outputs": [],
   "source": [
    "def remove_random_node(g, removal_size):\n",
    "    # remove node at random\n",
    "    for i in range(removal_size):\n",
    "        target = random.choice(list(g.nodes.keys()))\n",
    "        g.remove_node(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fOBE2rSgABQ7",
    "outputId": "be540701-e141-4faf-ac64-a86c0289ad32"
   },
   "outputs": [],
   "source": [
    "# load network\n",
    "G = nx.read_gml('Graphs/airlines.gml')\n",
    "# random attack\n",
    "random_attack(G, REMOVAL_SIZE, remove_random_node, 'random.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADrvia17ABQ8"
   },
   "source": [
    "## Targeted Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SIassUABwaMt"
   },
   "outputs": [],
   "source": [
    "def percentage_of_removed_links(G):\n",
    "    return int(len(G)/100)\n",
    "\n",
    "def get_by_index(sorted_dict, i):\n",
    "   return sorted_dict[i][0]\n",
    " \n",
    "\n",
    "def targeted_attack(g, sorted_dict, removal_size, img_name):\n",
    "    \n",
    "    graph = g.copy()\n",
    "    node_idx = 0\n",
    "    # network metrics\n",
    "    degree = []\n",
    "    #avg_out_degree = []\n",
    "    SCC = []\n",
    "    avg_closeness = []\n",
    "    avg_betweenness = []\n",
    "    avg_clustering = []\n",
    "    avg_eigvec_centrality = []\n",
    "    num_of_steps = []\n",
    "    \n",
    "    for percentage in trange(REMOVAL_COUNT):\n",
    "        # compute avg. degree\n",
    "        degree.append(sum([d for (n, d) in nx.degree(graph)]) / float(graph.number_of_nodes()))\n",
    "        #avg_out_degree.append(sum([d for (n, d) in graph.out_degree()]) / float(graph.number_of_nodes()))\n",
    "        # clustering\n",
    "        avg_clustering.append(nx.average_clustering(graph))\n",
    "        # largest strongly connected components\n",
    "        SCC.append(len(max(nx.strongly_connected_components(graph), key=len)))\n",
    "        # closeness\n",
    "        avg_closeness.append(np.average(list(nx.closeness_centrality(graph).values())))\n",
    "        # betweenness\n",
    "        avg_betweenness.append(np.average(list(nx.betweenness_centrality(graph).values())))\n",
    "        # eigenvector centrality (DOES NOT CONVERGE!)\n",
    "        # avg_eigvec_centrality.append(np.average(list(nx.eigenvector_centrality(graph,max_iter=100).values())))\n",
    "        # keep track of steps\n",
    "        num_of_steps.append(percentage)\n",
    "        # remove nodes\n",
    "        for i in range(REMOVAL_SIZE):\n",
    "            target = get_by_index(sorted_dict, node_idx)\n",
    "            graph.remove_node(target)\n",
    "            node_idx +=1\n",
    "    \n",
    "    # plot statistics\n",
    "    fig, axs = plt.subplots(3, figsize=(15,15))\n",
    "    fig.suptitle('Network statistics after attack')\n",
    "    axs[0].plot(num_of_steps, degree, color='blue', label='avg. degree')\n",
    "    #axs[0].plot(num_of_steps, avg_out_degree, color='cyan', label='avg. out degree')\n",
    "    axs[0].legend()\n",
    "    axs[0].set_ylabel('k')\n",
    "    axs[0].set_xlabel('% of removed nodes')\n",
    "    axs[0].set_yscale('log')\n",
    "    axs[1].plot(num_of_steps, SCC, color='red', label='SCC')\n",
    "    axs[1].set_ylabel('Giant component size')\n",
    "    axs[1].set_xlabel('% of removed nodes')\n",
    "    axs[1].set_yscale('log')\n",
    "    axs[1].legend()\n",
    "    axs[2].plot(num_of_steps, avg_closeness, color='green', label='avg. closeness')\n",
    "    axs[2].plot(num_of_steps, avg_betweenness, color='orange', label='avg. betweenness')\n",
    "    axs[2].plot(num_of_steps, avg_clustering, color='purple', label='avg. clustering')\n",
    "    #axs[2].plot(num_of_steps, avg_eigvec_centrality, color='brown', label='avg. eigvec. centr.')\n",
    "    axs[2].set_ylabel('CC,CB,C') #,EC\n",
    "    axs[2].set_xlabel('% of removed nodes')\n",
    "    axs[2].set_yscale('log')\n",
    "    axs[2].legend()\n",
    "    fig.savefig('Figures/robustness/' + img_name)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckxQ2GvEABQ-"
   },
   "source": [
    "### Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gtX2VdmkABQ_",
    "outputId": "a29746d2-85a7-4ced-92e3-d574e42035a5"
   },
   "outputs": [],
   "source": [
    "# load network\n",
    "G = nx.read_gml('Graphs/airlines.gml')\n",
    "# Optimisation: precompute closeness dict instead of doing it continuously on the fly\n",
    "sorted_betweenness = sorted(dict(nx.betweenness_centrality(G)).items(), key=itemgetter(1), reverse=True)\n",
    "# betweenness attack\n",
    "targeted_attack(G, sorted_betweenness, REMOVAL_SIZE, 'betweenness.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpTUNtRlABRA"
   },
   "source": [
    "### Closeness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jOb9PozwABRB",
    "outputId": "9155c4af-27bb-4027-a9fc-140ee13ffdf7"
   },
   "outputs": [],
   "source": [
    "# load network\n",
    "G = nx.read_gml('Graphs/airlines.gml')\n",
    "# Optimisation: precompute closeness dict instead of doing it continuously on the fly\n",
    "sorted_closeness = sorted(dict(nx.closeness_centrality(G)).items(), key=itemgetter(1), reverse=True)\n",
    "# closeness attack\n",
    "targeted_attack(G, sorted_closeness, REMOVAL_SIZE, 'closeness.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYPtrAlEABRC"
   },
   "source": [
    "### Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4IPqtP-JbAa0",
    "outputId": "5a35f140-7631-4020-c7b7-e24058892a33"
   },
   "outputs": [],
   "source": [
    "# load network\n",
    "G = nx.read_gml('Graphs/airlines.gml')\n",
    "# Optimisation: precompute degree dict instead of doing it continuously on the fly\n",
    "sorted_degree_dict = sorted(dict(nx.degree(G)).items(), key=itemgetter(1), reverse=True)\n",
    "# degree attack\n",
    "targeted_attack(G, sorted_degree_dict, REMOVAL_SIZE, 'degree.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4Nr2GKSABRF"
   },
   "source": [
    "### Eigenvector Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDdcOWeOxhys"
   },
   "source": [
    "*Note: Does not converge!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLjpaJU3ABRF"
   },
   "outputs": [],
   "source": [
    "# load network\n",
    "G = nx.read_gml('Graphs/airlines.gml')\n",
    "# Optimisation: precompute degree dict instead of doing it continuously on the fly\n",
    "sorted_eigvec_dict = sorted(dict(nx.eigenvector_centrality(G)).items(), key=itemgetter(1), reverse=True)\n",
    "# eigenvector centrality attack\n",
    "targeted_attack(G, sorted_eigvec_dict, REMOVAL_SIZE, 'eigvec.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMgyQfuiABRG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "robustness_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}